{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Python Libraries  \n",
    "\n",
    "import pandas as pd                         # for data manupulation                   \n",
    "import matplotlib.pyplot as plt             # for data visualization\n",
    "from sklearn.impute import SimpleImputer    # for data impution \n",
    "import numpy as np                          # for numeracal computation\n",
    "from linearmodels.panel import PanelOLS     # for statistical modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data as dataframe for analysis \n",
    "\n",
    "df = pd.read_excel('/Users/davidsokurov/Desktop/I.S./Data Analysis/Final I.S. Dataset.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is processed and analyzed in the following 4 steps:\n",
    "\n",
    "1. Data cleaning, wrangling and organization \n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Regression Modeling and Analysis\n",
    "4. Regression Diagnostic checks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Data cleaning, wrangling and organization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputes the variables Visitation and Tourism\n",
    "df['Visitation'] = df.groupby('Park')['Visitation'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['Tourism'] = df.groupby('Park')['Tourism'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total missing values are 51 (Visitation and Tourism)\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "total_missing_values = df.isnull().sum().sum()\n",
    "\n",
    "print(\"Total missing values:\", total_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of variables \n",
    "variable_list = df.columns.tolist()\n",
    "print(\"List of variables:\", variable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_parks = df['Park'].unique()\n",
    "unique_park_count = df['Park'].nunique()\n",
    "print(unique_park_count)\n",
    "print(unique_parks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIves the list of all missing values and their locations \n",
    "missing_values_df = df.isnull()\n",
    "\n",
    "missing_locations = pd.DataFrame([(row, col) for row in missing_values_df.index for col in missing_values_df.columns if missing_values_df.at[row, col]])\n",
    "print(\"Locations of missing values:\")\n",
    "print(missing_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the new dataset as a csv file\n",
    "df = df.to_csv(\"final_data.csv\", index=False)\n",
    "#df.to_excel(\"edited_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = df[\"Country\"].unique()\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for park, data in df.groupby('Park'):\n",
    "    plt.plot(data['Year'], data['Visitation'], label=park)\n",
    "\n",
    "plt.title('Visitation Trends Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Visitation')\n",
    "\n",
    "# Create a separate legend object\n",
    "legend = plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.figure(figsize=(15, 6))  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add numbers on bargraphs \n",
    "mean_visitation_by_country = df.groupby('Country')['Visitation'].mean()\n",
    "\n",
    "# Sort countries in ascending order based on mean visitation\n",
    "sorted_countries = mean_visitation_by_country.sort_values().index\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for country in sorted_countries:\n",
    "    plt.bar(country, mean_visitation_by_country[country], label=country)\n",
    "    plt.text(country, mean_visitation_by_country[country], f'{mean_visitation_by_country[country]:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Visitation Across Countries (Ascending Order)')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Mean Visitation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "df.groupby('Year')['Visitation'].mean().plot(marker='o')\n",
    "plt.title('Mean Visitation Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Visitation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE IT HORIZONTAL\n",
    "plt.figure(figsize=(15, 8))\n",
    "tourism_by_country = df.groupby('Country')['Tourism'].mean().sort_values(ascending=True)\n",
    "tourism_by_country.plot(kind='barh', color='skyblue')\n",
    "\n",
    "for index, value in enumerate(tourism_by_country):\n",
    "    plt.text(value, index, f'{value:,}', va='center', fontsize=10)\n",
    "\n",
    "plt.title('Total Tourism by Country')\n",
    "plt.xlabel('Total Tourism')\n",
    "plt.ylabel('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the list of unique countries\n",
    "countries = df['Country'].unique()\n",
    "\n",
    "# Create subplots for each country\n",
    "fig, axes = plt.subplots(nrows=len(countries), ncols=1, figsize=(10, 3 * len(countries)))\n",
    "\n",
    "# Iterate over countries and create scatter plots with trend lines\n",
    "for i, country in enumerate(countries):\n",
    "    country_data = df[df['Country'] == country]\n",
    "    \n",
    "    # Scatter Plot: Animation Popularity vs. Visitation\n",
    "    axes[i].scatter(x='AnimationPopularity', y='Visitation', data=country_data, alpha=0.5, label='Visitation')\n",
    "    \n",
    "    # Trend line for Animation Popularity vs. Visitation\n",
    "    z_visitation = np.polyfit(country_data['AnimationPopularity'], country_data['Visitation'], 1)\n",
    "    p_visitation = np.poly1d(z_visitation)\n",
    "    axes[i].plot(country_data['AnimationPopularity'], p_visitation(country_data['AnimationPopularity']), color='red')\n",
    "\n",
    "    # Scatter Plot: Animation Popularity vs. Tourism\n",
    "    axes[i].scatter(x='AnimationPopularity', y='Tourism', data=country_data, alpha=0.5, label='Tourism')\n",
    "    \n",
    "    # Trend line for Animation Popularity vs. Tourism\n",
    "    z_tourism = np.polyfit(country_data['AnimationPopularity'], country_data['Tourism'], 1)\n",
    "    p_tourism = np.poly1d(z_tourism)\n",
    "    axes[i].plot(country_data['AnimationPopularity'], p_tourism(country_data['AnimationPopularity']), color='blue')\n",
    "\n",
    "    axes[i].set_title(f'Scatter Plot: Animation Popularity, Visitation, and Tourism - {country}')\n",
    "    axes[i].set_xlabel('Animation Popularity')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n",
    "\n",
    "# Set the DataFrame index using the panel variables and sort it\n",
    "df.set_index(['Park', 'Year'], inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Create a PanelOLS model\n",
    "model = PanelOLS.from_formula('Visitation ~ AnimationPopularity + Tourism + GDP + Population', data=df)\n",
    "\n",
    "# Fit the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print regression results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Diagnostics Checks and Adjusting the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/davidsokurov/Desktop/I.S./Data Analysis/Final I.S. Dataset.xlsx')\n",
    "df.set_index([\"Park\", \"Year\"], inplace=True)\n",
    "\n",
    "\n",
    "df['Visitation'] = df.groupby('Park')['Visitation'].transform(lambda x: x.fillna(x.mean()))\n",
    "df['Tourism'] = df.groupby('Park')['Tourism'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df.index.get_level_values(\"Year\").to_list()\n",
    "df[\"Year\"] = pd.Categorical(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df[[\"AnimationPopularity\", \"Tourism\", \"GDP\", \"Population\"]].corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PooledOLS\n",
    "from linearmodels import PooledOLS\n",
    "import statsmodels.api as sm\n",
    "exog = sm.tools.tools.add_constant(df[\"AnimationPopularity\"])\n",
    "\n",
    "endog = df[\"Visitation\"]\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooledOLS_res = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "# Store values for checking homoskedasticity graphically\n",
    "fittedvals_pooled_OLS = pooledOLS_res.predict().fitted_values\n",
    "residuals_pooled_OLS = pooledOLS_res.resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3A. Homoskedasticity\n",
    "import matplotlib.pyplot as plt\n",
    " # 3A.1 Residuals-Plot for growing Variance Detection\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(fittedvals_pooled_OLS, residuals_pooled_OLS, color = \"blue\")\n",
    "ax.axhline(0, color = 'r', ls = '--')\n",
    "ax.set_xlabel(\"Predicted Values\", fontsize = 15)\n",
    "ax.set_ylabel(\"Residuals\", fontsize = 15)\n",
    "ax.set_title(\"Homoskedasticity Test\", fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3A.2 White-Test\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan\n",
    "\n",
    "# Assuming you have residuals_pooled_OLS from your previous code\n",
    "pooled_OLS_dataset = pd.concat([df, residuals_pooled_OLS.rename(\"residuals\")], axis=1)\n",
    "pooled_OLS_dataset = pooled_OLS_dataset.drop([\"Year\"], axis=1).fillna(0)\n",
    "exog = sm.tools.tools.add_constant(df[\"AnimationPopularity\"]).fillna(0)\n",
    "white_test_results = het_white(pooled_OLS_dataset[\"residuals\"], exog)\n",
    "labels = [\"LM-Stat\", \"LM p-val\", \"F-Stat\", \"F p-val\"] \n",
    "print(dict(zip(labels, white_test_results)))\n",
    "\n",
    "# 3A.3 Breusch-Pagan-Test\n",
    "breusch_pagan_test_results = het_breuschpagan(pooled_OLS_dataset[\"residuals\"], exog)\n",
    "labels = [\"LM-Stat\", \"LM p-val\", \"F-Stat\", \"F p-val\"] \n",
    "print(dict(zip(labels, breusch_pagan_test_results)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the statistical tests indicate that the assumption of homoskedasticity is likely violated, and there is evidence to support the presence of heteroskedasticity in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.B Non-Autocorrelation\n",
    "# Durbin-Watson-Test\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "durbin_watson_test_results = durbin_watson(pooled_OLS_dataset[\"residuals\"]) \n",
    "print(durbin_watson_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durbin-Watson statistic of 0.41 is significantly less than 2, indicating positive autocorrelation in the residuals. This suggests that there may be a pattern in the residuals that is not explained by the model, and there might be some temporal dependence between consecutive observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence, assumption 3b is also violated, so it seems that a FE-/RE-model will be more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels import PanelOLS\n",
    "from linearmodels import RandomEffects\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming df contains 'AnimationPopularity', 'Tourism', 'GDP', 'Population', and 'Visitation'\n",
    "exog_vars = ['AnimationPopularity', 'Tourism', 'Population']\n",
    "exog = sm.tools.tools.add_constant(df[exog_vars])\n",
    "endog = df['Visitation']\n",
    "\n",
    "# Random effects model\n",
    "model_re = RandomEffects(endog, exog, check_rank=False) \n",
    "re_res = model_re.fit() \n",
    "\n",
    "# Fixed effects model\n",
    "model_fe = PanelOLS(endog, exog, entity_effects=True) \n",
    "fe_res = model_fe.fit() \n",
    "\n",
    "# Print results\n",
    "print(re_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fe_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, normal_ad\n",
    "from scipy import stats\n",
    "\n",
    "# Log transformation of the dependent variable\n",
    "df['Log_Visitation'] = np.log(df['Visitation'])\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df[['AnimationPopularity', 'Tourism', 'GDPPerCapita',]]\n",
    "y = df['Log_Visitation']\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(model.summary())\n",
    "\n",
    "# Test for multicollinearity\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF):\")\n",
    "print(calculate_vif(X))\n",
    "\n",
    "# Test for homoskedasticity\n",
    "_, p_homoskedasticity, _, _ = het_breuschpagan(model.resid, X)\n",
    "print(\"\\nHomoskedasticity Test (Breusch-Pagan):\")\n",
    "print(\"p-value:\", p_homoskedasticity)\n",
    "\n",
    "# Test for normality of residuals\n",
    "p_normality = stats.normaltest(model.resid)[1]\n",
    "print(\"\\nNormality Test (Jarque-Bera):\")\n",
    "print(\"p-value:\", p_normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, normal_ad\n",
    "from scipy import stats\n",
    "\n",
    "# Log transformation of the dependent variable\n",
    "df['Log_Visitation'] = np.log(df['Visitation'])\n",
    "\n",
    "# Log transformation of independent variables\n",
    "df['Log_Tourism'] = np.log(df['Tourism'])\n",
    "df['Log_GDPPerCapita'] = np.log(df['GDPPerCapita'])\n",
    "\n",
    "# Define independent and dependent variables\n",
    "X = df[['AnimationPopularity', 'Log_Tourism', 'Log_GDPPerCapita']]\n",
    "y = df['Log_Visitation']\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(model.summary())\n",
    "\n",
    "# Test for multicollinearity\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF):\")\n",
    "print(calculate_vif(X))\n",
    "\n",
    "# Test for homoskedasticity\n",
    "_, p_homoskedasticity, _, _ = het_breuschpagan(model.resid, X)\n",
    "print(\"\\nHomoskedasticity Test (Breusch-Pagan):\")\n",
    "print(\"p-value:\", p_homoskedasticity)\n",
    "\n",
    "# Test for normality of residuals\n",
    "p_normality = stats.normaltest(model.resid)[1]\n",
    "print(\"\\nNormality Test (Jarque-Bera):\")\n",
    "print(\"p-value:\", p_normality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
